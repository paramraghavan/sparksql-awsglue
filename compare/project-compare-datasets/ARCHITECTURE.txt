╔══════════════════════════════════════════════════════════════════════════════╗
║                    ARCHITECTURE & WORKFLOW DIAGRAM                           ║
╚══════════════════════════════════════════════════════════════════════════════╝

┌──────────────────────────────────────────────────────────────────────────────┐
│ SYSTEM ARCHITECTURE                                                          │
└──────────────────────────────────────────────────────────────────────────────┘

                           ┌─────────────────┐
                           │   AWS S3        │
                           │  (Your Data)    │
                           └────────┬────────┘
                                    │
                    ┌───────────────┴───────────────┐
                    │                               │
            ┌───────▼───────┐              ┌───────▼───────┐
            │  Dataset 1    │              │  Dataset 2    │
            │ 50GB+ Parquet │              │ 50GB+ Parquet │
            │ 200+ columns  │              │ 200+ columns  │
            └───────┬───────┘              └───────┬───────┘
                    │                               │
                    └───────────────┬───────────────┘
                                    │
                         ┌──────────▼──────────┐
                         │    EMR Cluster      │
                         │  ┌──────────────┐   │
                         │  │   Master     │   │
                         │  └──────────────┘   │
                         │  ┌──────────────┐   │
                         │  │  Core Nodes  │   │
                         │  │  (5-10 nodes)│   │
                         │  └──────────────┘   │
                         │  ┌──────────────┐   │
                         │  │ Task Nodes   │   │
                         │  │  (optional)  │   │
                         │  └──────────────┘   │
                         └──────────┬──────────┘
                                    │
                    ┌───────────────┼───────────────┐
                    │               │               │
            ┌───────▼───────┐ ┌────▼────┐ ┌───────▼────────┐
            │ HTML Report   │ │ Samples │ │  Statistics    │
            │   (S3)        │ │  (S3)   │ │    (Logs)      │
            └───────────────┘ └─────────┘ └────────────────┘


┌──────────────────────────────────────────────────────────────────────────────┐
│ DATA FLOW                                                                    │
└──────────────────────────────────────────────────────────────────────────────┘

1. LOAD PHASE
   ┌──────────────┐
   │   Read       │    ┌─→ Dataset 1 (Parquet) → DataFrame 1
   │  Parquet     │────┤
   │   Files      │    └─→ Dataset 2 (Parquet) → DataFrame 2
   └──────────────┘

2. SCHEMA COMPARISON
   ┌──────────────┐
   │   Compare    │    ┌─→ Common columns
   │   Schemas    │────┼─→ Columns only in DF1
   └──────────────┘    └─→ Columns only in DF2

3. KEY MATCHING
   ┌──────────────┐
   │   Create     │    ┌─→ Composite key from key columns
   │ Composite    │────┤   (e.g., id||date||customer)
   │    Keys      │    └─→ Used for all joins
   └──────────────┘

4. RECORD IDENTIFICATION
   ┌──────────────┐
   │    Join      │    ┌─→ Records only in DF1
   │  on Keys     │────┼─→ Records only in DF2
   └──────────────┘    └─→ Matching records (Inner join)

5. COLUMN COMPARISON (for matching records)
   ┌──────────────┐
   │   Compare    │    For each column:
   │   Column     │    ┌─→ Count differences
   │   Values     │────┼─→ Calculate % difference
   └──────────────┘    └─→ Collect samples

6. REPORT GENERATION
   ┌──────────────┐
   │  Generate    │    ┌─→ HTML report with metrics
   │    HTML      │────┼─→ Interactive tables
   │   Report     │    └─→ Sample differences
   └──────────────┘


┌──────────────────────────────────────────────────────────────────────────────┐
│ EXECUTION WORKFLOW                                                           │
└──────────────────────────────────────────────────────────────────────────────┘

┌─────────────┐
│    START    │
└──────┬──────┘
       │
       ▼
┌─────────────────────┐
│  Initialize Spark   │  • Configure executors
│    Session          │  • Set shuffle partitions
└──────┬──────────────┘  • Enable adaptive execution
       │
       ▼
┌─────────────────────┐
│  Load Datasets      │  • Read Parquet files
│  (Parallel)         │  • Add source column
└──────┬──────────────┘  • Count records
       │
       ▼
┌─────────────────────┐
│  Schema Analysis    │  • Compare column lists
└──────┬──────────────┘  • Identify differences
       │
       ▼
┌─────────────────────┐
│  Record Count       │  • Count DF1
│  Comparison         │  • Count DF2
└──────┬──────────────┘  • Calculate difference
       │
       ▼
┌─────────────────────┐
│  Create Composite   │  • Concatenate key columns
│  Keys               │  • Handle nulls
└──────┬──────────────┘  • Create key index
       │
       ├──────────────────┐
       │                  │
       ▼                  ▼
┌─────────────┐    ┌─────────────┐
│DF1 Keys     │    │DF2 Keys     │
│(Distinct)   │    │(Distinct)   │
└──────┬──────┘    └──────┬──────┘
       │                  │
       └────────┬─────────┘
                │
       ┌────────┴─────────┐
       │                  │
       ▼                  ▼
┌─────────────┐    ┌─────────────┐
│ Left Anti   │    │ Left Anti   │
│   Join      │    │   Join      │
└──────┬──────┘    └──────┬──────┘
       │                  │
       ▼                  ▼
┌─────────────┐    ┌─────────────┐
│Records only │    │Records only │
│  in DF1     │    │  in DF2     │
└──────┬──────┘    └──────┬──────┘
       │                  │
       └────────┬─────────┘
                │
                ▼
┌─────────────────────┐
│  Inner Join on      │  • Match records by key
│  Composite Key      │  • Cache result
└──────┬──────────────┘  • Count matches
       │
       ▼
┌─────────────────────┐
│  For Each Column:   │  ┌─→ Cast to string
│  Compare Values     │  ├─→ Count differences
└──────┬──────────────┘  ├─→ Calculate %
       │                 └─→ Sample differences
       ▼
┌─────────────────────┐
│  Aggregate Results  │  • Column differences list
└──────┬──────────────┘  • Sample records
       │                 • Statistics
       ▼
┌─────────────────────┐
│  Generate HTML      │  • Build report
│  Report             │  • Add interactivity
└──────┬──────────────┘  • Write to S3
       │
       ▼
┌─────────────┐
│  Save       │  • Unique records (samples)
│  Artifacts  │  • Summary stats
└──────┬──────┘  • Report file
       │
       ▼
┌─────────────┐
│     END     │
└─────────────┘


┌──────────────────────────────────────────────────────────────────────────────┐
│ PARALLEL PROCESSING                                                          │
└──────────────────────────────────────────────────────────────────────────────┘

Dataset 1 (50GB)                    Dataset 2 (50GB)
      │                                   │
      ├─→ Partition 1                    ├─→ Partition 1
      ├─→ Partition 2                    ├─→ Partition 2
      ├─→ Partition 3                    ├─→ Partition 3
      ├─→    ...                          ├─→    ...
      └─→ Partition 400                  └─→ Partition 400
           │                                  │
           └──────────┬─────────────────────┘
                      │
           ┌──────────┴──────────┐
           │   Shuffle & Join    │  (Distributed across executors)
           └──────────┬──────────┘
                      │
           ┌──────────┴──────────┐
           │   Comparison        │  (Parallel column comparisons)
           └──────────┬──────────┘
                      │
                  ┌───▼───┐
                  │Results│
                  └───────┘


┌──────────────────────────────────────────────────────────────────────────────┐
│ OPTIMIZATION STRATEGIES                                                      │
└──────────────────────────────────────────────────────────────────────────────┘

1. PARTITIONING
   ┌────────────────────┐
   │ Input Data (50GB)  │
   └─────────┬──────────┘
             │ Partition by key ranges
             ▼
   ┌───┬───┬───┬───┬───┐
   │P1 │P2 │P3 │...│P400│  (125MB each)
   └───┴───┴───┴───┴───┘
             │
             ▼
   Distributed across 20 executors
   (20 partitions per executor)

2. CACHING STRATEGY
   • Cache key DataFrames before joins
   • Cache joined results for multiple aggregations
   • Unpersist when no longer needed

3. ADAPTIVE QUERY EXECUTION
   • Dynamically coalesces partitions
   • Optimizes skewed joins
   • Converts sort-merge to broadcast

4. COLUMN PRUNING
   • Only read required columns
   • Skip columns not in comparison
   • Reduce shuffle data

5. PREDICATE PUSHDOWN
   • Filter at Parquet level
   • Reduce data read from S3
   • Minimize network transfer


┌──────────────────────────────────────────────────────────────────────────────┐
│ MEMORY DISTRIBUTION (Example: 20 executors × 8GB)                           │
└──────────────────────────────────────────────────────────────────────────────┘

Total Executor Memory: 160GB
├─ Storage Memory (30%):  48GB  → Cached DataFrames
├─ Execution Memory (50%): 80GB → Joins, aggregations, shuffles
└─ Reserved (20%):        32GB  → JVM overhead, system

Each Executor (8GB):
├─ Storage: 2.4GB
├─ Execution: 4GB
└─ Reserved: 1.6GB


┌──────────────────────────────────────────────────────────────────────────────┐
│ KEY TECHNOLOGIES                                                             │
└──────────────────────────────────────────────────────────────────────────────┘

┌─────────────┐   ┌─────────────┐   ┌─────────────┐   ┌─────────────┐
│   PySpark   │   │    YARN     │   │   Parquet   │   │     S3      │
│             │   │             │   │             │   │             │
│ Distributed │   │  Resource   │   │ Columnar    │   │   Object    │
│ Computing   │   │  Manager    │   │  Storage    │   │   Storage   │
└─────────────┘   └─────────────┘   └─────────────┘   └─────────────┘

┌─────────────┐   ┌─────────────┐   ┌─────────────┐
│    EMR      │   │  Adaptive   │   │    HTML     │
│             │   │   Query     │   │             │
│  Managed    │   │  Execution  │   │  Reporting  │
│  Hadoop     │   │    (AQE)    │   │             │
└─────────────┘   └─────────────┘   └─────────────┘


═══════════════════════════════════════════════════════════════════════════════

This architecture provides:
✓ Scalability: Handle 50GB+ files
✓ Performance: 20-40 min execution time
✓ Reliability: Fault-tolerant distributed processing
✓ Cost-effective: Optimized resource usage
✓ Comprehensive: Detailed comparison and reporting
