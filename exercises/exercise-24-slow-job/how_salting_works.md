## Why Table2 Needs Replication - Explained with Example

You're right to question this! Let me explain with a concrete example.

### The Salting Problem

**Original situation (WITHOUT salting):**

```
Table1 (570M rows with CUSIP='ABC', DATE='2024-01-01')
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CUSIPâ”‚ EFFECTIVEDATEâ”‚ amount  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ABC  â”‚ 2024-01-01   â”‚ 100     â”‚  â† All 570M rows
â”‚ ABC  â”‚ 2024-01-01   â”‚ 200     â”‚     go to ONE partition
â”‚ ABC  â”‚ 2024-01-01   â”‚ 300     â”‚     (SKEW!)
â”‚ ...  â”‚ ...          â”‚ ...     â”‚
â”‚ ABC  â”‚ 2024-01-01   â”‚ 999     â”‚  (570 million rows)
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Table2 (10K rows with same key)
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CUSIPâ”‚ EFFECTIVEDATEâ”‚ price   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ABC  â”‚ 2024-01-01   â”‚ 50.00   â”‚  â† All 10K rows
â”‚ ABC  â”‚ 2024-01-01   â”‚ 50.10   â”‚     also in ONE partition
â”‚ ...  â”‚ ...          â”‚ ...     â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

JOIN â†’ 570M Ã— 10K = 5.7 TRILLION comparisons in ONE executor! ğŸ’¥
```

### The Salting Solution

**Goal**: Split this massive join across multiple partitions

**Step 1: Salt Table1 (RANDOM salt)**

```python
table1_salted = table1.withColumn(
    "salt",
    (F.rand() * 100).cast("int")  # Random 0-99
)
```

Result:

```
Table1 with RANDOM salt
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
â”‚ CUSIPâ”‚ EFFECTIVEDATEâ”‚ amount â”‚ salt â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
â”‚ ABC  â”‚ 2024-01-01   â”‚ 100    â”‚  37  â”‚  â† Random salt
â”‚ ABC  â”‚ 2024-01-01   â”‚ 200    â”‚  82  â”‚  â† Random salt
â”‚ ABC  â”‚ 2024-01-01   â”‚ 300    â”‚   5  â”‚  â† Random salt
â”‚ ABC  â”‚ 2024-01-01   â”‚ 400    â”‚  37  â”‚  â† Random salt
â”‚ ...  â”‚ ...          â”‚ ...    â”‚ ...  â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜

Now distributed across ~100 partitions (by salt value)
Each partition has ~5.7M rows (570M / 100)
```

**Step 2: The Problem - How to Join?**

Table1 rows now have **random** salt values. For the join to work:

- Table1 row with `(CUSIP=ABC, DATE=2024-01-01, salt=37)` needs to join with...
- Table2 row with `(CUSIP=ABC, DATE=2024-01-01, salt=37)` â† **same salt!**

But Table2 doesn't know which salt values Table1 will randomly pick!

### Why Replication is Necessary

Since Table1 uses **random** salts (0-99), Table2 needs to have copies with **ALL possible salts** (0-99):

```python
table2_salted = table2.withColumn(
    "salt",
    F.explode(F.array([F.lit(i) for i in range(100)]))  # ALL salts 0-99
)
```

Result:

```
Table2 REPLICATED with ALL salt values
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
â”‚ CUSIPâ”‚ EFFECTIVEDATEâ”‚ price  â”‚ salt â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
â”‚ ABC  â”‚ 2024-01-01   â”‚ 50.00  â”‚  0   â”‚  â† Same row...
â”‚ ABC  â”‚ 2024-01-01   â”‚ 50.00  â”‚  1   â”‚  â† replicated...
â”‚ ABC  â”‚ 2024-01-01   â”‚ 50.00  â”‚  2   â”‚  â† 100 times...
â”‚ ...  â”‚ ...          â”‚ ...    â”‚ ...  â”‚
â”‚ ABC  â”‚ 2024-01-01   â”‚ 50.00  â”‚ 99   â”‚  â† with different salt
â”‚ ABC  â”‚ 2024-01-01   â”‚ 50.10  â”‚  0   â”‚  â† Next row...
â”‚ ABC  â”‚ 2024-01-01   â”‚ 50.10  â”‚  1   â”‚  â† also replicated...
â”‚ ...  â”‚ ...          â”‚ ...    â”‚ ...  â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜

Original 10K rows â†’ Now 1M rows (10K Ã— 100)
```

### The Join Now Works

```
JOIN on (CUSIP, EFFECTIVEDATE, salt)

Partition 0 (salt=0):
  Table1: ~5.7M rows with salt=0
  Table2: 10K rows with salt=0
  â†’ 5.7M Ã— 10K = 57B comparisons âœ“

Partition 37 (salt=37):
  Table1: ~5.7M rows with salt=37
  Table2: 10K rows with salt=37
  â†’ 5.7M Ã— 10K = 57B comparisons âœ“

... (100 partitions total)

All partitions run in PARALLEL! ğŸš€
```

### Visual Comparison

**Without Salting:**

```
Single Executor doing ALL the work:
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% load
[                                    ] 0% load
[                                    ] 0% load
[                                    ] 0% load
... (99 idle executors)
```

**With Salting (SALT_FACTOR=100):**

```
Work distributed across 100 executors:
[â–ˆâ–ˆâ–ˆ] 1% of work
[â–ˆâ–ˆâ–ˆ] 1% of work
[â–ˆâ–ˆâ–ˆ] 1% of work
[â–ˆâ–ˆâ–ˆ] 1% of work
... (100 executors, all working)
```

### Why the Math Works

Original total work:

- 570M Ã— 10K = **5.7 trillion comparisons**

After salting:

- 570M Ã— (10K Ã— 100) = **57 trillion comparisons**

**Wait, that's 10x more work!?**

Yes, but:

- Original: 1 executor does 5.7T comparisons â±ï¸ **40+ minutes**
- Salted: 100 executors each do 57B comparisons â±ï¸ **~5 minutes** (if parallel)

The **replication overhead** (10x more comparisons) is offset by **100x parallelism**.

### Alternative: Why Not Salt Table2 Randomly Too?

```python
# What if we do this?
table2_salted = table2.withColumn("salt", (F.rand() * 100).cast("int"))
```

**Problem**: Rows won't match!

```
Table1:
â”‚ ABC  â”‚ 2024-01-01   â”‚ 100    â”‚  37  â”‚

Table2:
â”‚ ABC  â”‚ 2024-01-01   â”‚ 50.00  â”‚  82  â”‚  â† Different salt!

JOIN fails! No match because salt 37 â‰  82
```

### Summary

**Why replicate Table2?**

1. Table1 gets **random** salt (0-99) to distribute rows
2. Table2 must have copies with **all** salts (0-99) to match any Table1 row
3. This ensures every Table1 row finds its matching Table2 row
4. Trade-off: 100x replication overhead for 100x parallelism gain

**SALT_FACTOR=1000 means:**

- Table2 replicated 1000 times (instead of 100)
- Better parallelism (1000 partitions instead of 100)
- But 10x more memory/shuffle overhead
